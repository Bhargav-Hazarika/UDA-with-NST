{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv0PqGEAfu4R",
        "outputId": "aded7cf9-edb8-4042-bfea-519b05054245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base paths\n",
        "GDRIVE_BASE = \"/content/drive/MyDrive/NST Dataset/filter_preproc\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pillow tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtHs4RFof3uF",
        "outputId": "eaef4029-8ffe-4775-dedd-a6f4c8695464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0YTETSsWEq3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mean_std(feat, eps=1e-5):\n",
        "    size = feat.size()\n",
        "    N, C = size[:2]\n",
        "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
        "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
        "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
        "    return feat_mean, feat_std\n",
        "\n",
        "def adain(content_feat, style_feat):\n",
        "    c_mean, c_std = calc_mean_std(content_feat)\n",
        "    s_mean, s_std = calc_mean_std(style_feat)\n",
        "    normalized = (content_feat - c_mean) / c_std\n",
        "    return normalized * s_std + s_mean\n"
      ],
      "metadata": {
        "id": "U-3F1e7KS8id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG encoder (truncated at relu4_1)\n",
        "# from torchvision.models import vgg19\n",
        "\n",
        "# vgg = vgg19(pretrained=False)\n",
        "# vgg.load_state_dict(torch.load(\"vgg_normalised.pth\"))\n",
        "# encoder = nn.Sequential(*list(vgg.features.children())[:21])\n",
        "\n",
        "# decoder = torch.load(\"decoder.pth\")\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# encoder = encoder.to(device).eval()\n",
        "# decoder = decoder.to(device).eval()"
      ],
      "metadata": {
        "id": "_Sd2tZGHTHOB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg_encoder():\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    cfg = [64, 64, 'M',\n",
        "           128, 128, 'M',\n",
        "           256, 256, 256, 256, 'M',\n",
        "           512, 512, 512, 512]  # stop at relu4_1\n",
        "\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            layers += [conv, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "\n",
        "    return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "a61f7UR5TJ40"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = build_vgg_encoder()\n",
        "# state_dict = torch.load(\"vgg_normalised.pth\")\n",
        "\n",
        "# encoder.load_state_dict(state_dict)\n",
        "# encoder.eval()"
      ],
      "metadata": {
        "id": "PXNniG_IJobS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = nn.Sequential(\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 3, (3, 3)),\n",
        ")\n",
        "\n",
        "vgg = nn.Sequential(\n",
        "    nn.Conv2d(3, 3, (1, 1)),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(3, 64, (3, 3)),\n",
        "    nn.ReLU(),  # relu1-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(),  # relu1-2\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 128, (3, 3)),\n",
        "    nn.ReLU(),  # relu2-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(),  # relu2-2\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-4\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-1, this is the last layer used\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-4\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu5-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu5-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu5-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU()  # relu5-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "RGO8U4LvJsue"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"vgg_normalised.pth\")\n",
        "vgg.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar0eKS2hKSFd",
        "outputId": "01818509-2241-4d1a-eba9-1e1be1e241fa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = nn.Sequential(*list(vgg.children())[:31])\n",
        "encoder.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxJlSNtnKVC7",
        "outputId": "5a1c3076-085f-40b7-eb69-6a9c85b7f944"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (1): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (3): ReLU()\n",
              "  (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (6): ReLU()\n",
              "  (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
              "  (8): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (10): ReLU()\n",
              "  (11): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (13): ReLU()\n",
              "  (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
              "  (15): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (17): ReLU()\n",
              "  (18): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (20): ReLU()\n",
              "  (21): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (23): ReLU()\n",
              "  (24): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (26): ReLU()\n",
              "  (27): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
              "  (28): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (29): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (30): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.load_state_dict(torch.load(\"decoder.pth\"))\n",
        "decoder.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OlKxVtcL5ET",
        "outputId": "4cf4f427-b527-42e3-c303-4c66f43e9169"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (2): ReLU()\n",
              "  (3): Upsample(scale_factor=2.0, mode='nearest')\n",
              "  (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (6): ReLU()\n",
              "  (7): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (9): ReLU()\n",
              "  (10): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (12): ReLU()\n",
              "  (13): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (15): ReLU()\n",
              "  (16): Upsample(scale_factor=2.0, mode='nearest')\n",
              "  (17): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (19): ReLU()\n",
              "  (20): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (22): ReLU()\n",
              "  (23): Upsample(scale_factor=2.0, mode='nearest')\n",
              "  (24): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (25): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (26): ReLU()\n",
              "  (27): ReflectionPad2d((1, 1, 1, 1))\n",
              "  (28): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity check"
      ],
      "metadata": {
        "id": "OQ9K98bdL-rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "with torch.no_grad():\n",
        "    f = encoder(x)\n",
        "    y = decoder(f)\n",
        "\n",
        "print(f.shape)  # should be [1, 512, 32, 32]\n",
        "print(y.shape)  # should be [1, 3, 256, 256]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzZ_pDnIL7w3",
        "outputId": "b66a5aed-545c-47bc-e37e-0484046b48d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 32, 32])\n",
            "torch.Size([1, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "encoder = encoder.to(device).eval()\n",
        "decoder = decoder.to(device).eval()"
      ],
      "metadata": {
        "id": "zu8GXRajMAFQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Transform"
      ],
      "metadata": {
        "id": "rdmr7NFnMixT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(512),\n",
        "    transforms.CenterCrop(512),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_image(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return transform(img).unsqueeze(0).to(device)\n"
      ],
      "metadata": {
        "id": "yvFpvwMsMdWV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def stylize(content_path, style_path, alpha=1.0):\n",
        "    content = load_image(content_path)\n",
        "    style = load_image(style_path)\n",
        "\n",
        "    content_feat = encoder(content)\n",
        "    style_feat = encoder(style)\n",
        "\n",
        "    t = adain(content_feat, style_feat)\n",
        "    t = alpha * t + (1 - alpha) * content_feat\n",
        "\n",
        "    out = decoder(t)\n",
        "    return out.clamp(0, 1)"
      ],
      "metadata": {
        "id": "3PRGapdTNSxf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_image_files(root, exts={\".jpg\", \".jpeg\", \".png\"}):\n",
        "    files = []\n",
        "    for dirpath, _, filenames in os.walk(root):\n",
        "        for fn in filenames:\n",
        "            if os.path.splitext(fn)[1].lower() in exts:\n",
        "                files.append(os.path.join(dirpath, fn))\n",
        "    return sorted(files)\n"
      ],
      "metadata": {
        "id": "vlei9js5QLf3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_dir = GDRIVE_BASE + \"/preproc/images_jpeg\"\n",
        "style_dir = GDRIVE_BASE + \"/styles\"\n",
        "out_dir = GDRIVE_BASE + \"/stylized\"\n",
        "\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# content_files = sorted(os.listdir(content_dir))[:20]\n",
        "# style_files   = sorted(os.listdir(style_dir))\n",
        "content_files = sorted([\n",
        "    f for f in os.listdir(content_dir)\n",
        "    if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
        "])[:20]\n",
        "\n",
        "style_files = collect_image_files(style_dir)\n",
        "\n",
        "\n",
        "NUM_STYLES_PER_IMAGE = 2  # configurable\n",
        "\n",
        "for cf in tqdm(content_files, desc=\"AdaIN stylization\"):\n",
        "    content_path = os.path.join(content_dir, cf)\n",
        "\n",
        "    for k in range(NUM_STYLES_PER_IMAGE):\n",
        "        # style_name = style_files[(hash(cf) + k) % len(style_files)]\n",
        "        # style_path = os.path.join(style_dir, style_name)\n",
        "        style_path = style_files[(hash(cf) + k) % len(style_files)]\n",
        "\n",
        "        out = stylize(content_path, style_path, alpha=1.0)\n",
        "\n",
        "        out_name = cf.replace(\".jpg\", f\"_s{k}.jpg\")\n",
        "        out_path = os.path.join(out_dir, out_name)\n",
        "\n",
        "        transforms.ToPILImage()(out.squeeze(0)).save(out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivUk5yE3NWj0",
        "outputId": "2faedba0-35e6-450d-a381-39da8a8383a6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AdaIN stylization: 100%|██████████| 20/20 [05:50<00:00, 17.52s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOLoTOF8PHkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}