{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wI0y3vrd6ilthIXPrwo8C1Ex5ZFf3Msg",
      "authorship_tag": "ABX9TyPGPX14Mi5Rzedq3ZS940b9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhargav-Hazarika/UDA-with-NST/blob/main/NST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dREMBU54yJcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904f07d8-b8e7-4470-a086-20a3c092487d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base paths\n",
        "GDRIVE_BASE = \"/content/drive/MyDrive/NST Dataset/filter_preproc\"\n",
        "RAW_ROOTS = [\n",
        "  \"/content/drive/MyDrive/NST Dataset/Northern_Renaissance\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/High_Renaissance\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Cubism\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Early_Renaissance\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Color_Field_Painting\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Contemporary_Realism\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Baroque\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Art_Nouveau_Modern\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Analytical_Cubism\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Action_painting\",\n",
        "  \"/content/drive/MyDrive/NST Dataset/Abstract_Expressionism\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base = GDRIVE_BASE # '/content/preprocess'\n",
        "os.makedirs(base, exist_ok=True)\n",
        "os.makedirs(os.path.join(base,\"original_raw\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(base,\"preproc\",\"images_jpeg\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(base,\"manifests\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(base,\"stylized\"), exist_ok=True)  # optional\n",
        "os.makedirs(os.path.join(base,\"logs\"), exist_ok=True)\n",
        "\n",
        "print(\"Created folder structure under\", base)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo4yTGhtL0ht",
        "outputId": "47fd2bbb-f483-496f-b805-a5dad50ff8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder structure under /content/drive/MyDrive/NST Dataset/filter_preproc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juhEMwxIbm11",
        "outputId": "aedfd023-2c13-445f-9565-6a16d05f59a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imagehash) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from imagehash) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.16.3)\n",
            "Downloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagehash\n",
            "Successfully installed imagehash-4.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing core\n",
        "import os, hashlib, pathlib, time, sys\n",
        "from PIL import Image, ImageFile\n",
        "import imagehash\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "kANaxcWwMJV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG\n",
        "RES = 256\n",
        "MIN_SIDE = 128\n",
        "JPEG_QUALITY = 92\n",
        "PHASH_FUNC = imagehash.phash\n",
        "# base = '/content/preprocess'\n",
        "BASE = GDRIVE_BASE\n",
        "SRC_DIRS = RAW_ROOTS  # from earlier cell\n",
        "OUT_DIR = os.path.join(BASE,\"preproc\",\"images_jpeg\")\n",
        "MANIFEST_CSV = os.path.join(BASE,\"manifests\",\"manifest.csv\")\n",
        "MANIFEST_PQ = os.path.join(BASE,\"manifests\",\"manifest.parquet\")\n",
        "LOGFILE = os.path.join(BASE,\"logs\",\"preproc_log.txt\")"
      ],
      "metadata": {
        "id": "sM6hM-x3brpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpers\n",
        "def sha256_file(path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path,\"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def process_and_save(in_path, out_path, res=RES):\n",
        "    try:\n",
        "        with Image.open(in_path) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            w,h = im.size\n",
        "            if min(w,h) < MIN_SIDE:\n",
        "                return {\"valid\": False, \"notes\":\"too_small\", \"width\":w, \"height\":h}\n",
        "            # center crop square\n",
        "            side = min(w,h)\n",
        "            left = (w-side)//2\n",
        "            top = (h-side)//2\n",
        "            im = im.crop((left, top, left+side, top+side)).resize((res,res), Image.LANCZOS)\n",
        "            ph = str(PHASH_FUNC(im))\n",
        "            # save\n",
        "            im.save(out_path, \"JPEG\", quality=JPEG_QUALITY, optimize=True)\n",
        "            sha_proc = sha256_file(out_path)\n",
        "            return {\"valid\":True, \"sha_proc\":sha_proc, \"phash\":ph, \"width\":res, \"height\":res}\n",
        "    except Exception as e:\n",
        "        return {\"valid\":False, \"notes\":f\"error:{e}\"}"
      ],
      "metadata": {
        "id": "yTXNuztYcAyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load existing manifest if present (resume support)\n",
        "if os.path.exists(MANIFEST_PQ):\n",
        "    manifest = pd.read_parquet(MANIFEST_PQ)\n",
        "else:\n",
        "    manifest = pd.DataFrame(columns=[\n",
        "        \"id\",\"orig_path\",\"proc_path\",\"sha_orig\",\"sha_proc\",\"phash\",\"width\",\"height\",\"valid\",\"notes\",\"source\",\"timestamp\"\n",
        "    ])"
      ],
      "metadata": {
        "id": "Jwmr20lJczK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build list of candidate files\n",
        "exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tiff\"}\n",
        "files = []\n",
        "for src in SRC_DIRS:\n",
        "    for p in pathlib.Path(src).rglob(\"*\"):\n",
        "        if p.suffix.lower() in exts:\n",
        "            files.append(str(p))\n",
        "files = sorted(files)"
      ],
      "metadata": {
        "id": "2hgW7XaUc6Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set of already-processed originals to skip\n",
        "processed_orig = set(manifest['orig_path'].astype(str).tolist()) if not manifest.empty else set()\n",
        "start_idx = len(manifest)"
      ],
      "metadata": {
        "id": "-wS7yb11ftK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "pbar = tqdm(files, desc=\"Preprocess pass\")\n",
        "for i, fp in enumerate(files):\n",
        "    if fp in processed_orig:\n",
        "        pbar.update(1)\n",
        "        continue\n",
        "    idx = start_idx + len(rows) + 1\n",
        "    out_name = f\"{idx:06d}.jpg\"\n",
        "    out_path = os.path.join(OUT_DIR, out_name)\n",
        "    sha_orig = sha256_file(fp)\n",
        "    resu = process_and_save(fp, out_path, res=RES)\n",
        "    row = {\n",
        "        \"id\": f\"{idx:06d}\",\n",
        "        \"orig_path\": fp,\n",
        "        \"proc_path\": out_path,\n",
        "        \"sha_orig\": sha_orig,\n",
        "        \"sha_proc\": resu.get(\"sha_proc\",\"\"),\n",
        "        \"phash\": resu.get(\"phash\",\"\"),\n",
        "        \"width\": resu.get(\"width\",\"\"),\n",
        "        \"height\": resu.get(\"height\",\"\"),\n",
        "        \"valid\": resu.get(\"valid\",False),\n",
        "        \"notes\": resu.get(\"notes\",\"\"),\n",
        "        \"source\": pathlib.Path(fp).parts[-3] if len(pathlib.Path(fp).parts) >=3 else pathlib.Path(fp).parts[0],\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "    rows.append(row)\n",
        "    pbar.update(1)\n",
        "\n",
        "if rows:\n",
        "    manifest = pd.concat([manifest, pd.DataFrame(rows)], ignore_index=True)\n",
        "    # Save both formats\n",
        "    manifest.to_parquet(MANIFEST_PQ, index=False)\n",
        "    manifest.to_csv(MANIFEST_CSV, index=False)\n",
        "    print(\"Appended\", len(rows), \"rows. Manifest saved.\")\n",
        "else:\n",
        "    print(\"No new files processed. Manifest unchanged.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWFdczKpfwrW",
        "outputId": "7acdf0c3-8df5-4fec-d6b4-67fc67f30ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocess pass: 100%|██████████| 21195/21195 [3:52:07<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appended 21195 rows. Manifest saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dedupe"
      ],
      "metadata": {
        "id": "WwXjAOVarw0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MANIFEST_PQ = os.path.join(GDRIVE_BASE,\"manifests\",\"manifest.parquet\")\n",
        "manifest = pd.read_parquet(MANIFEST_PQ)\n",
        "\n",
        "# Exact duplicates (same sha_proc)\n",
        "dups = manifest[manifest.duplicated(\"sha_proc\", keep=False)]\n",
        "print(\"Exact dupe groups:\", dups.shape[0])\n",
        "\n",
        "# Keep first occurrence for exact duplicates\n",
        "manifest = manifest.drop_duplicates(\"sha_proc\", keep=\"first\").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4gYI32zagFbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a519d237-a15d-4fe0-ab07-8d7ea4e4c2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact dupe groups: 198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Near-duplicate via pHash (bucket by phash prefix to reduce comparisons)\n",
        "from collections import defaultdict\n",
        "buckets = defaultdict(list)\n",
        "for i, r in manifest.iterrows():\n",
        "    ph = r['phash'] if pd.notnull(r['phash']) else \"\"\n",
        "    bucket_key = ph[:6]  # first chars to bucket (tunable)\n",
        "    buckets[bucket_key].append(i)\n",
        "\n",
        "to_drop = set()\n",
        "PHAMM_TH = 6  # Hamming threshold\n",
        "for bucket in buckets.values():\n",
        "    if len(bucket) <= 1:\n",
        "        continue\n",
        "    for i in range(len(bucket)):\n",
        "        for j in range(i+1, len(bucket)):\n",
        "            ph1 = manifest.loc[bucket[i],\"phash\"]\n",
        "            ph2 = manifest.loc[bucket[j],\"phash\"]\n",
        "            if not ph1 or not ph2: continue\n",
        "            # compute Hamming\n",
        "            h1 = imagehash.hex_to_hash(ph1)\n",
        "            h2 = imagehash.hex_to_hash(ph2)\n",
        "            if h1 - h2 <= PHAMM_TH:\n",
        "                # pick which to drop: keep higher orig file size (proxy for quality)\n",
        "                sz_i = os.path.getsize(manifest.loc[bucket[i],\"orig_path\"])\n",
        "                sz_j = os.path.getsize(manifest.loc[bucket[j],\"orig_path\"])\n",
        "                drop_idx = bucket[j] if sz_i >= sz_j else bucket[i]\n",
        "                to_drop.add(drop_idx)\n",
        "\n",
        "print(\"Near-duplicates to drop:\", len(to_drop))\n",
        "manifest = manifest.drop(index=list(to_drop)).reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-9i5_-Ur_o8",
        "outputId": "4773e042-db12-40c5-fcaa-cb4dadbe3859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Near-duplicates to drop: 54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reassign new deterministic ids based on sorted proc_path for stability (optional)\n",
        "manifest = manifest.sort_values(\"proc_path\").reset_index(drop=True)\n",
        "manifest['id'] = [(i+1) for i in range(len(manifest))]\n",
        "manifest['id'] = manifest['id'].apply(lambda x: f\"{x:06d}\")\n",
        "\n",
        "# Save updated manifest\n",
        "manifest.to_parquet(MANIFEST_PQ, index=False)\n",
        "manifest.to_csv(os.path.join(GDRIVE_BASE,\"manifests\",\"manifest.csv\"), index=False)\n",
        "print(\"Dedup done. Manifest now has\", manifest.shape[0], \"rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBazpcdesZIx",
        "outputId": "0135e781-b97b-4258-bd9a-5c46c0237f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dedup done. Manifest now has 21040 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling"
      ],
      "metadata": {
        "id": "QbNuCRIfs6VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np, os\n",
        "MANIFEST_PQ = os.path.join(GDRIVE_BASE,\"manifests\",\"manifest.parquet\")\n",
        "manifest = pd.read_parquet(MANIFEST_PQ)\n",
        "\n",
        "n_total = len(manifest)\n",
        "n_small = min(2000, n_total)    # tune\n",
        "n_medium = min(15000, n_total) # tune\n",
        "\n",
        "manifest = manifest.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle deterministically\n",
        "manifest.iloc[:n_small].to_csv(os.path.join(GDRIVE_BASE,\"manifests\",\"sampling_small.csv\"), index=False)\n",
        "manifest.iloc[:n_medium].to_csv(os.path.join(GDRIVE_BASE,\"manifests\",\"sampling_medium.csv\"), index=False)\n",
        "manifest.to_csv(os.path.join(GDRIVE_BASE,\"manifests\",\"sampling_full.csv\"), index=False)\n",
        "\n",
        "print(\"Sampling files written. small:\", n_small, \"medium:\", n_medium, \"full:\", n_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEoVJ_Nssk-_",
        "outputId": "e4f6313a-eb15-4325-d86f-00981c423aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling files written. small: 2000 medium: 15000 full: 21040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check size"
      ],
      "metadata": {
        "id": "RaeclPgntY2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MANIFEST_PQ = os.path.join(GDRIVE_BASE,\"manifests\",\"manifest.parquet\")\n",
        "m = pd.read_parquet(MANIFEST_PQ)\n",
        "sizes = [os.path.getsize(p) for p in m['proc_path']]\n",
        "avg = sum(sizes)/len(sizes)\n",
        "total_bytes = avg * len(sizes)\n",
        "print(\"Images:\", len(sizes))\n",
        "print(\"Avg per image (MB):\", avg/1024/1024)\n",
        "print(\"Estimated total (GB):\", total_bytes/1024/1024/1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJZ_-Xd0tCf9",
        "outputId": "77c707e7-b775-4433-e4b0-f2cff166be7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images: 21040\n",
            "Avg per image (MB): 0.02402570320172908\n",
            "Estimated total (GB): 0.4936531204730272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1n8dx05tdCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}